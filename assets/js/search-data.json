{
  
    
        "post0": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://jimypbr.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://jimypbr.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Experiments with Julia",
            "content": "SIMD Support . Since version 0.3 Julia has some vectorisation capabilities that can exploit SIMD instructions when executing loops. It seems to require some nudging though. There are macros that are a bit like the pragmas in OpenMP. . Example 1. SAXPY . function saxpy(a::Float32, x::Array{Float32,1}, y::Array{Float32,1}) n = length(x) for i = 1:n y[i] += a*x[i] end end . Sadly, in version 0.3.10 this obvious candidate does not auto-vectorise. You can inspect how this code has compiled nicely in Julia by using the macros @code_llvm to see the LLVM IR or @code_native to see the ASM. The ASM produced is: . Source line: 48 mov R8, QWORD PTR [RSI + 16] xor R11D, R11D xor ECX, ECX cmp RCX, R8 jae 65 cmp RCX, QWORD PTR [RDI + 16] jae 55 lea R10, QWORD PTR [4*R11] mov RAX, QWORD PTR [RSI + 8] sub RAX, R10 mov RDX, QWORD PTR [RDI + 8] sub RDX, R10 movss XMM1, DWORD PTR [RDX] mulss XMM1, XMM0 addss XMM1, DWORD PTR [RAX] movss DWORD PTR [RAX], XMM1 dec R11 inc RCX cmp R9, RCX jne -72 pop RBP ret movabs RAX, 140636405232096 mov RDI, QWORD PTR [RAX] movabs RAX, 140636390845696 mov ESI, 48 call RAX . Note the scalar instructions movss, mulss, and addss. . Example 2: SAXPY + SIMD . To make it generate vectorised instructions you have to use the explicit vectorisation macros @simd and @inbounds macros. @simd gives the compiler license to vectorise without checking the legality of the transformation. @inbounds is an optimisation that turns off subscript checking, because subscript checking might throw an exception and so isn’t vectorisable. . function axpy(a::Float32, x::Array{Float32,1}, y::Array{Float32,1}) n = length(x) @simd for i = 1:n @inbounds y[i] += a*x[i] end end . This now compiles with SIMD instructions: . ... Source line: 48 mov R8, QWORD PTR [RDI + 8] mov R9, QWORD PTR [RSI + 8] xor EDI, EDI mov RSI, RAX and RSI, -8 je 79 pshufd XMM1, XMM0, 0 # xmm1 = xmm0[0,0,0,0] xor EDI, EDI lea RCX, QWORD PTR [4*RDI] mov RDX, R8 sub RDX, RCX movups XMM3, XMMWORD PTR [RDX] movups XMM2, XMMWORD PTR [RDX + 16] mulps XMM3, XMM1 mov RDX, R9 sub RDX, RCX movups XMM5, XMMWORD PTR [RDX] movups XMM4, XMMWORD PTR [RDX + 16] addps XMM5, XMM3 movups XMMWORD PTR [RDX], XMM5 mulps XMM2, XMM1 addps XMM2, XMM4 movups XMMWORD PTR [RDX + 16], XMM2 add RDI, -8 mov RCX, RSI add RCX, RDI jne -69 mov RDI, RSI sub RAX, RDI je 41 ... . Note the instructions movups, addps, mulps… (English: move, unaligned, packed, single-precision). Packed =&gt; Vector. . We can also see from the LLVM IR: . define void @julia_axpy_21664(float, %jl_value_t*, %jl_value_t*) { ... br label %vector.body vector.body: ; preds = %vector.body, %vector.ph %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ] %25 = getelementptr float* %20, i64 %index, !dbg !4955 %26 = bitcast float* %25 to &lt;4 x float&gt;* %wide.load = load &lt;4 x float&gt;* %26, align 4 %.sum18 = or i64 %index, 4 %27 = getelementptr float* %20, i64 %.sum18 %28 = bitcast float* %27 to &lt;4 x float&gt;* %wide.load9 = load &lt;4 x float&gt;* %28, align 4 %29 = getelementptr float* %24, i64 %index, !dbg !4955 %30 = bitcast float* %29 to &lt;4 x float&gt;* %wide.load10 = load &lt;4 x float&gt;* %30, align 4 %31 = getelementptr float* %24, i64 %.sum18 %32 = bitcast float* %31 to &lt;4 x float&gt;* %wide.load11 = load &lt;4 x float&gt;* %32, align 4 %33 = fmul &lt;4 x float&gt; %wide.load10, %broadcast.splat13 %34 = fmul &lt;4 x float&gt; %wide.load11, %broadcast.splat13 %35 = fadd &lt;4 x float&gt; %wide.load, %33 %36 = fadd &lt;4 x float&gt; %wide.load9, %34 store &lt;4 x float&gt; %35, &lt;4 x float&gt;* %26, align 4 store &lt;4 x float&gt; %36, &lt;4 x float&gt;* %28, align 4 %index.next = add i64 %index, 8 %37 = icmp eq i64 %index.next, %n.vec br i1 %37, label %middle.block, label %vector.body middle.block: ; preds = %vector.body, %if %resume.val = phi i64 [ 0, %if ], [ %n.vec, %vector.body ] %cmp.n = icmp eq i64 %15, %resume.val br i1 %cmp.n, label %L7, label %L ... . Timing of a function is easy to do: . x = rand(Float32, 10000000) y = rand(Float32, 10000000) a = float32(0.1) @time axpy(a,x,y) . However, you probably want to run this more than once since the first time you call a function, Julia JITs it so the timing won’t be representative. Here are the timings of axpy with and without @simd with length(x) == 10000000: . @simd? Time (s) . yes | 0.006527373 | . no | 0.013172804 | . Setup: Hardware: Intel(R) Core(TM) i5-3570 CPU @ 3.40GHz (AVX) Julia version: 0.3.11 . Example 3: SAXPY + Implicit vectorisation . In my experiments, I found that it is sometimes possible to get implicit vectorisation by using just @inbounds to disable bounds checking: . function axpy(a::Float32, x::Array{Float32,1}, y::Array{Float32,1}) n = length(x) for i = 1:n @inbounds y[i] += a*x[i] end end . This generates the same ASM as Example 2. Other simple cases have required @simd as well, so explicit vectorisation seems to be the only option at the moment. . SIMD Limitations in Julia . No SIMD functions. Function calls have to be inlined. Julia can manage to inline short functions itself. | Code must be type-stable. This means that there isn’t implicit type conversion in the loop. This will prevent vectorisation and probably make it run slow serially too. | SIMD macro doesn’t have the bells and whistles of the OpenMP SIMD pragma. | Doesn’t appear to be any way to specify alignment of memory. | No outer loop vectorisation. | I can’t find any diagnostic information about how things were optimised. | Does handle any branching besides some ifelse function. | . More Info on Vectorisation . See Intel page Vectorization in Julia. . Case Study: Fitzhugh-Nagamo PDE . Experiment with a non-trivial example of a PDE solver using the reaction-diffusion system described by: . [ begin{eqnarray} frac{ partial u}{ partial t} &amp;=&amp; a nabla^2 u + u - u^3 - v - k tau frac{ partial v}{ partial t} &amp;=&amp; b nabla^2 v + u - v end{eqnarray}] . With Neumann boundary conditions, boundary of [1,1]^2, N=100^2, and T=[0.,10.]. This example is based on this online python example. I implement this in C++ and Julia and compare the performance and the vectorisation. $y=x^2$. . Here is the code in Julia: . Click to expand… function fitzhugh_nagumo(size, T) # Define the constants const aa = 2.8e-4 const bb = 5.0e-3 const τ = 0.1 const κ = -0.005 const dx = 2.0 / size const dt = 0.9 * dx^2 / 2.0 const invdx2 = 1.0 / dx^2 const dt_τ = dt / τ # Random initial fields u_old = rand(Float64, (size,size)) v_old = rand(Float64, (size,size)) u_new = Array(Float64, (size,size)) v_new = Array(Float64, (size,size)) for t = 0.0 : dt : T for j = 2:size-1 for i = 2:size-1 Δu = invdx2 * (u_old[i+1,j] + u_old[i-1,j] + u_old[i,j+1] + u_old[i,j-1] - 4*u_old[i,j]) Δv = invdx2 * (v_old[i+1,j] + v_old[i-1,j] + v_old[i,j+1] + v_old[i,j-1] - 4*v_old[i,j]) u_new[i,j] = u_old[i,j] + dt * (aa*Δu + u_old[i,j] - u_old[i,j]*u_old[i,j]*u_old[i,j] - v_old[i,j] + κ) v_new[i,j] = v_old[i,j] + dt_τ * (bb*Δv + u_old[i,j] - v_old[i,j]) end end for i = 1:size u_new[i,1] = u_new[i,2] u_new[i,size] = u_new[i,size-1] v_new[i,1] = v_new[i,2] v_new[i,size] = v_new[i,size-1] end for j = 1:size u_new[1,j] = u_new[2,j] u_new[size,j] = u_new[size-1,j] v_new[1,j] = v_new[2,j] v_new[size,j] = v_new[size-1,j] end # swap new and old u_new, u_old = u_old, u_new v_new, v_old = v_old, v_new end return (u_old, v_old) end . Here is the code in C++. . Click to expand… #include &lt;iostream&gt; #include &lt;random&gt; #include &lt;algorithm&gt; // swap #define N 100 std::random_device rd; std::mt19937 mt(rd()); double fitzhugh_nagumo(double T) { // Define the constants const double aa = 2.8e-4; const double bb = 5.0e-3; const double tau = 0.1; const double kappa = -0.005; const double dx = 2.0 / N; const double dt = 0.9 * dx*dx / 2.0; const double invdx2 = 1.0 / (dx*dx); const double dt_tau = dt / tau; // Random initial fields double u_old[N][N]; double v_old[N][N]; double u_new[N][N]; double v_new[N][N]; std::uniform_real_distribution&lt;double&gt; rng(0.,1.); for (int i = 0; i &lt; N; ++i) { for (int j = 0; j &lt; N; ++j) { u_old[i][j] = rng(mt); v_old[i][j] = rng(mt); } } // Solver int Nt = (int) (T / dt); std::cout &lt;&lt; &quot;Nt = &quot; &lt;&lt; Nt &lt;&lt; std::endl; for (int t = 0; t &lt; Nt; ++t) { // evolve inner coordinates for (int i = 1; i &lt; N-1; ++i) { for (int j = 1; j &lt; N-1; ++j) { double delta_u = invdx2 * (u_old[i+1][j] + u_old[i-1][j] + u_old[i][j+1] + u_old[i][j-1] - 4*u_old[i][j]); double delta_v = invdx2 * (v_old[i+1][j] + v_old[i-1][j] + v_old[i][j+1] + v_old[i][j-1] - 4*v_old[i][j]); u_new[i][j] = u_old[i][j] + dt * (aa*delta_u + u_old[i][j] - u_old[i][j]*u_old[i][j]*u_old[i][j] - v_old[i][j] + kappa); v_new[i]After i[j] = v_old[i][j] + dt_tau * (bb * delta_v + u_old[i][j] - v_old[i][j]); } } // neumann boundary conditions for (int i = 0; i &lt; N; ++i) { u_new[i][0] = u_new[i][1]; u_new[i][N-1] = u_new[i][N-2]; v_new[i][0] = v_new[i][1]; v_new[i][N-1] = v_new[i][N-2]; } for (int j = 0; j &lt; N; ++j) { u_new[0][j] = u_new[1][j]; u_new[N-1][j] = u_new[N-2][j]; v_new[0][j] = v_new[1][j]; v_new[N-1][j] = v_new[N-2][j]; } // Swap old and new std::swap(u_new, u_old); std::swap(v_new, v_old); } return u_old[0][0]; } . Results . Setup: . Hardware: Intel(R) Core(TM) i5-3570 CPU @ 3.40GHz (AVX) | Julia version: 0.3.10 | C++ Compiler: g++4.8 | . Language Notes Time (s) . Julia | None | 5.993 | . Julia | @inbounds | 3.105 | . Julia | @inbounds + @simd | 3.0603 | . C++ | -O0 -std=c++11 | 22.790 | . C++ | -Ofast -std=c++11 -fno-tree-vectorize -fno-tree-slp-vectorize | 3.2096 | . C++ | -Ofast -std=c++11 | 2.142 | . The best time in C++ is only 1.4x better than the best time in Julia. Inspecting the ASM of Julia + @inbounds + @simd shows that even with these macros Julia is still not generating vector instructions. :(. If I disable vectorisation in the C++ compiler, the times between Julia and C++ are much closer. This suggests that Julia could get even higher performance if it could generate vector instructions. I suppose that newer versions of Julia will improve this in the future. I find these results very impressive nonetheless. It will be worth trying with a newer LLVM version too. . Notes . The thing holding back performance in the Julia code was the use of u[i,j]^3 instead of u[i,j]*u[i,j]*u[i,j]. The former version compiles to a call of pow(double, double) from libm! The latter does what you expect. This is a known bug. Fixed when Julia is built against LLVM 3.6. Version I’m using is built with LLVM v3.4. .",
            "url": "https://jimypbr.github.io/blog/julia/c++/simd/2015/11/21/julia.html",
            "relUrl": "/julia/c++/simd/2015/11/21/julia.html",
            "date": " • Nov 21, 2015"
        }
        
    
  
    
        ,"post3": {
            "title": "Hello",
            "content": "Typical hello world first blog post… .",
            "url": "https://jimypbr.github.io/blog/2015/11/20/hello.html",
            "relUrl": "/2015/11/20/hello.html",
            "date": " • Nov 20, 2015"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jimypbr.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jimypbr.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}